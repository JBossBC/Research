# HTTP2.0


+ 对1.0协议的完全兼容
+ 性能的大幅度提升


## http2.0优化内容


+ 二进制分帧-http2.0的基石

    http2.0之所以能够突破http1.0标准的性能限制，改进传输性能，实现低延迟和高吞吐量，就是因为其增加了二进制分帧层

    + 帧包含部分:类型Type,长度Length,标记Flags,流标识Stream和frame payload有效载荷
    + 消息:一个完整的请求或者响应，比如请求，响应等，由一个或多个Frame组成

     流是连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流ID冲突，客户端发起的流具有奇数ID，服务端发起的流具有偶数ID

     流标识是描述二进制frame的格式，使得每个frame能够基于http2发送，与流标识联系的是一个流，每个流是一个逻辑联系，一个独立的双向的frame存在于客户端和服务器端之间的http2连接中。一个http2连接上可包含多个并发打开的流。这个并发流的数量能够由客户端设置。

      在二进制分帧层上，http2.0会将所有传输消息分割为更小的消息和帧，并对他们采用二进制格式的编码将其封装，新增的二进制分帧层同时也能保证http的各种动词，方法，首部不受影响，兼容上一代http标准。其中，http1.x的首部信息header封装到headers帧中，而request body 将被封装到Data帧中。

+ 多路复用/连接共享

在http1.1中，浏览器客户端在同一实践，针对同一域名下的请求有数量的限制，超过限制数量的请求会被阻塞，这也是为何一些站点会有多个静态资源CDN域名的原因之一。

而http2.0中的多路复用优化了这一性能，多路复用允许同时通过单一的http/2连接发起多重的请求-响应消息。有了新的分帧机制后，http/2不再依赖多个TCP连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，这些帧可以交错(乱序发送)，还可以分优先级，最后在另一端把他们重新组合起来。

http2.0的连接都是持久化的，而且客户端与服务器之间也只需要一个连接(每个域名一个连接)即可。http2连接可以承载数十或数百个流的复用，**多路复用意味着来自很多流的数据包能够混合在一起通过同样的连接传输，当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流进行组装**

+ 头部压缩

http1.x的头带有大量信息，而且每次都要重新发送。http/2使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。

对于相同的数据，不再通过每次请求和响应发送，通信期间几乎不会改变通用键值对(用户代理、可接受的媒体类型，等等)只需发送一次。

事实上，如果请求中不包含首部，那么首部开销就是0bytes，此时所有首部都自动使用之前请求发送的首部

如果首部发生了变化，则只需要将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表再http2.0的连接存续期内始终存在，由客户端和服务器共同渐进地更新。

需要注意的是，http 2.0关注的是首部压缩，而我们常用的gzip等是报文内容（body）的压缩，二者不仅不冲突，且能够一起达到更好的压缩效果。



**压缩原理:用header字段表中的索引代替实际的header(http/2的hpack算法使用一份索引表来定义常用的http header,把常用的http header存放在表里，请求的时候便只需要发送在表里的索引位置即可)**





+ 请求优先级

把http消息划分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的优先值:0代表最高优先级;2的31次方-1表示最低优先级

服务器可以根据流的优先级，控制资源分配，而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。高优先级的流都应该优先发送，但又不是绝对的。绝对地遵守可能会引入首队阻塞地问题:高优先级地请求慢导致阻塞其他资源的交付???

分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。客户端会指定哪个流是最重要的，有一些依赖参数，这样一个流可以依赖另外一个流。优先级别可以在运行时动态改变，当用户滚动页面时，可以告诉浏览器哪个图像是最重要的，你也可以在一组流中进行优先筛选，能够突然抓住重点流。

●优先级最高：主要的html

●优先级高：CSS文件

●优先级中：js文件

●优先级低：图片


+ 服务端推送

服务端可以对一个客户端请求发送多个响应，服务器向客户端推送资源无需客户端明确地请求，并且，服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求地步骤。

正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。** Server Push 让 http1.x 时代使用内嵌资源的优化手段变得没有意义；如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo 以及样式表，因为它知道客户端会用到这些东西，这相当于在一个 HTML 文档内集合了所有的资源。**

不过与之相比，服务器推送还有一个很大的优势：可以缓存！也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能



注意两点：

1、推送遵循同源策略；

2、这种服务端的推送是基于客户端的请求响应来确定的。

当服务端需要主动推送某个资源时，便会发送一个 Frame Type 为 PUSH_PROMISE 的 Frame，里面带了 PUSH 需要新建的 Stream ID。意思是告诉客户端：接下来我要用这个 ID 向你发送东西，客户端准备好接着。客户端解析 Frame 时，发现它是一个 PUSH_PROMISE 类型，便会准备接收服务端要推送的流。




## http2.0性能瓶颈(和我想得一样)
启用http2.0后会给性能带来很大的提升，但同时也会带来新的性能瓶颈。因为现在所有的压力集中在底层一个TCP连接之上，TCP很可能就是下一个性能瓶颈，比如TCP分组的队首阻塞问题，单个TCP packet丢失导致整个连接阻塞，无法逃避，此时所有消息都会受到影响。未来，服务器端针对http 2.0下的TCP配置优化至关重要。
